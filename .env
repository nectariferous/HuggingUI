# MongoDB Configuration
MONGODB_URL=mongodb+srv://likhonsheikh:likhonsheikh@cluster0.vnbo62a.mongodb.net/
MONGODB_DB_NAME=chat-ui
MONGODB_DIRECT_CONNECTION=false

# Cookie Configuration
COOKIE_NAME=hf-chat
TRUSTED_EMAIL_HEADER= # only set this if you understand the implications

# Hugging Face API Configuration
HF_TOKEN=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
HF_API_ROOT=https://api-inference.huggingface.co/models
HF_ACCESS_TOKEN= #LEGACY! Use HF_TOKEN instead

# API Keys Configuration
OPENAI_API_KEY=#your openai api key here
ANTHROPIC_API_KEY=#your anthropic api key here
CLOUDFLARE_ACCOUNT_ID=#your cloudflare account id here
CLOUDFLARE_API_TOKEN=#your cloudflare api token here
COHERE_API_TOKEN=#your cohere api token here

# Web Search Functionality (choose one)
YDC_API_KEY=#your docs.you.com api key here
SERPER_API_KEY=#your serper.dev api key here
SERPAPI_KEY=#your serpapi key here
SERPSTACK_API_KEY=#your serpstack api key here
SEARCHAPI_KEY=#your searchapi api key here
USE_LOCAL_WEBSEARCH=#set to true to parse google results yourself, overrides other API keys
SEARXNG_QUERY_URL=# where '<query>' will be replaced with query keywords

# Playwright Configuration
PLAYWRIGHT_ADBLOCKER=true
WEBSEARCH_ALLOWLIST=`[]` # if defined, allow websites from only this list
WEBSEARCH_BLOCKLIST=`[]` # if defined, block websites from this list
WEBSEARCH_JAVASCRIPT=true # Enable to improve website compatibility

# OpenID Configuration
OPENID_CONFIG=`{
  "PROVIDER_URL": "",
  "CLIENT_ID": "",
  "CLIENT_SECRET": "",
  "SCOPES": "",
  "NAME_CLAIM": ""
}`

# Legacy OpenID Settings (prefer the config above)
OPENID_CLIENT_ID=
OPENID_CLIENT_SECRET=
OPENID_SCOPES="openid profile"
OPENID_NAME_CLAIM="name"
OPENID_PROVIDER_URL=https://huggingface.co
OPENID_TOLERANCE=
OPENID_RESOURCE=

# mTLS Configuration
USE_CLIENT_CERTIFICATE=false
CERT_PATH=
KEY_PATH=
CA_PATH=
CLIENT_KEY_PASSWORD=
REJECT_UNAUTHORIZED=true

# Text Embedding Models
TEXT_EMBEDDING=`{
  "name": "Xenova/gte-small",
  "displayName": "Xenova/gte-small",
  "description": "Local embedding model running on the server.",
  "chunkCharLength": 512,
  "endpoints": [
    { "type": "transformersjs" }
  ]
}`

# Model Configurations
MODELS=`[
  {                {
                    "meta-llama/Meta-Llama-3.1-70B-Instruct": 124,
                    "mistralai/Mixtral-8x7B-Instruct-v0.1": 125,
                    "meta-llama/Meta-Llama-3.1-405B-Instruct-FP8": 126,
                    "mistralai/Mistral-7B-Instruct-v0.3": 125,
                    "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO": 125,
                    "CohereForAI/c4ai-command-r-plus": 125,
                    "microsoft/Phi-3-mini-4k-instruct": 125,
                    "01-ai/Yi-1.5-34B-Chat": 125
                }
    "websiteUrl": "https://ai.meta.com/llama/",
    "userMessageToken": "",
    "userMessageEndToken": " [/INST] ",
    "assistantMessageToken": "",
    "assistantMessageEndToken": " </s><s>[INST] ",
    "preprompt": " ",
    "chatPromptTemplate": "<s>[INST] <<SYS>>\n{{preprompt}}\n<</SYS>>\n\n{{#each messages}}{{#ifUser}}{{content}} [/INST] {{/ifUser}}{{#ifAssistant}}{{content}} </s><s>[INST] {{/ifAssistant}}{{/each}}",
    "promptExamples": [
      {
        "title": "Write an email from bullet list",
        "prompt": "As a restaurant owner, write a professional supplier to get these products every week: \n\n- Wine (x10)\n- Eggs (x24)\n- Bread (x12)"
      },
      {
        "title": "Code a snake game",
        "prompt": "Code a basic snake game in python, give explanations for each step."
      },
      {
        "title": "Assist in a task",
        "prompt": "How do I make a delicious lemon cheesecake?"
      }
    ],
    "parameters": {
      "temperature": 0.1,
      "top_p": 0.95,
      "repetition_penalty": 1.2,
      "top_k": 50,
      "truncate": 3072,
      "max_new_tokens": 1024
    },
    "endpoints": [{
      "type": "tgi",
      "url": "http://chat-flame-backend:8080/model/70b-chat/"
    }]
  },
  {
    "name": "codellama/CodeLlama-34b-Instruct-hf",
    "displayName": "codellama/CodeLlama-34b-Instruct-hf",
    "description": "Code Llama, a state of the art code model from Meta.",
    "websiteUrl": "https://about.fb.com/news/2023/08/code-llama-ai-for-coding/",
    "userMessageToken": "",
    "userMessageEndToken": " [/INST] ",
    "assistantMessageToken": "",
    "assistantMessageEndToken": " </s><s>[INST] ",
    "preprompt": " ",
    "chatPromptTemplate": "<s>[INST] <<SYS>>\n{{preprompt}}\n<</SYS>>\n\n{{#each messages}}{{#ifUser}}{{content}} [/INST] {{/ifUser}}{{#ifAssistant}}{{content}} </s><s>[INST] {{/ifAssistant}}{{/each}}",
    "promptExamples": [
      {
        "title": "Fibonacci in Python",
        "prompt": "Write a python function to calculate the nth fibonacci number."
      },
      {
        "title": "JavaScript promises",
        "prompt": "How can I wait for multiple JavaScript promises to fulfill before doing something with their values?"
      },
      {
        "title": "Rust filesystem",
        "prompt": "How can I load a file from disk in Rust?"
      }
    ],
    "parameters": {
      "temperature": 0.1,
      "top_p": 0.95,
      "repetition_penalty": 1.2,
      "top_k": 50,
      "truncate": 4096,
      "max_new_tokens": 4096
    },
    "endpoints": [{
      "type": "tgi",
      "url": "http://chat-flame-backend:8080/model/34b-code/"
    }]
  },
  {
    "name": "tiiuae/falcon-180B-chat",
    "displayName": "tiiuae/falcon-180B-chat",
    "description": "Falcon-180B is a 180B parameters causal decoder-only model built by TII and trained on 3,500B tokens.",
    "websiteUrl": "https://www.tii.ae/news/technology-innovation-institute-introduces-worlds-most-powerful-open-llm-falcon-180b",
    "preprompt": " ",
    "chatPromptTemplate": "System: {{preprompt}}\nUser:{{#each messages}}{{#ifUser}}{{content}}\nFalcon:{{/ifUser}}{{#ifAssistant}}{{content}}\nUser:{{/ifAssistant}}{{/each}}",
    "parameters": {
      "temperature": 0.1,
      "top_p": 0.95,
      "repetition_penalty": 1.2,
      "top_k": 50,
      "truncate": 1000,
      "max_new_tokens": 1024,
      "stop": ["User:"]
    },
    "promptExamples": [
      {
        "title": "Write an email from bullet list",
        "prompt": "As a restaurant owner, write a professional email to the supplier to get these products every week: \n\n- Wine (x10)\n- Eggs (x24)\n- Bread (x12)"
      },
      {
        "title": "Code a snake game",
        "prompt": "Code a basic snake game in python, give explanations for each step."
      },
      {
        "title": "Assist in a task",
        "prompt": "How do I make a delicious lemon cheesecake?"
      }
    ]
  },
  {
    "name": "mistralai/Mistral-7B-Instruct-v0.1",
    "displayName": "mistralai/Mistral-7B-Instruct-v0.1",
    "description": "Mistral 7B is a new Apache 2.0 model, released by Mistral AI that outperforms Llama2 13B in benchmarks.",
    "websiteUrl": "https://mistral.ai/news/announcing-mistral-7b/",
    "preprompt": "",
    "chatPromptTemplate": "<s>{{#each messages}}{{#ifUser}}[INST] {{#if @first}}{{#if @root.preprompt}}{{@root.preprompt}}\n{{/if}}{{/if}}{{content}} [/INST]{{/ifUser}}{{#ifAssistant}}{{content}}</s>{{/ifAssistant}}{{/each}}",
    "parameters": {
      "temperature": 0.1,
      "top_p": 0.95,
      "repetition_penalty": 1.2,
      "top_k": 50,
      "truncate": 1000,
      "max_new_tokens": 1024,
      "stop": ["</s>[INST]"]
    },
    "promptExamples": [
      {
        "title": "Write an email from bullet list",
        "prompt": "As a restaurant owner, write a professional email to the supplier to get these products every week: \n\n- Wine (x10)\n- Eggs (x24)\n- Bread (x12)"
      },
      {
        "title": "Code a snake game",
        "prompt": "Code a basic snake game in python, give explanations for each step."
      },
      {
        "title": "Assist in a task",
        "prompt": "How do I make a delicious lemon cheesecake?"
      }
    ]
  }
]`

# Translation Service Configuration
TRANSLATION=`{
  "service": "openai",
  "prompt": "Translate the following text to {language}:\n\n",
  "params": {}
}`

# Agent Settings
AGENT_SETTINGS=`{
  "functions": [],
  "enabled": false,
  "settings": {
    "openai_model": "gpt-4-0613"
  }
}`

# Default Model
DEFAULT_MODEL=meta-llama/Llama-2-70b-chat-hf

# Client Application Configuration
NEXT_PUBLIC_USE_GOOGLE_ANALYTICS=false
NEXT_PUBLIC_USE_HOTJAR=false
